



## 推断

```bash
python3 inference_video.py --exp=1 --video=video.mp4 

```



默认的权重文件在train_log里





训练命令

```bash
python -m torchrun train.py --world_size=1 --local_rank=0

screen -S egy_train torchrun train.py --world_size=1 --local_rank=0 --batch_size=64
```



### 结果记录

使用项目训练代码，vimeo数据集训练复现，得到模型权重参数，在多个中测试结果如下：

vimeo_interp_test

Avg PSNR: 35.035979413110226 SSIM: 0.9756986498832703



UCF100 测试集

Avg PSNR: 35.24737353269929 SSIM: 0.9689498543739319



ATD12K_test

Avg PSNR: 28.775512916087578 SSIM: 0.9535548686981201







## benchmark使用

在benchmark中写好了不同数据集的测试代码，注意修改其中读取模型的目录，以及数据集的目录。

###### 

## 代码梳理

模型

RIFE 整体模型

IFNet 光流预测网络







作者在论文中描述的IFNet是用来预测光流的，其结构由三个IFBlock组成。

IFNet.py文件中为IFNet模型相关代码。IFBlock类 定义了作者在论文中提出的**IFNet**的小模块





在refine中的Unet定义的forward中进行融合





## Lomar局部重建



主要流程：

1. 获得U-Net的生成图片pred
2. 将pred，以及相关mask信息送入mae中
3. 使用mask信息产生图片块，送入重建模块重建
4. 返回重建图片块并替换到原来位置
5. 计算损失









## 遮挡mask指导策略

在光流预测阶段，已经得到了遮挡的mask。

mask图中的黑色与白色代表了遮挡区域，而最终生成的图片中往往是那些运动大的，在遮挡区域的部分图像质量不好，因此可以根据遮挡区域的mask来指导图像的重建，只对那些与遮挡相关的部分进行重建处理。



1. 获得遮挡mask
2. 使用特定算法，获得一个根据mask确定需要重建的区域的变量
3. 使用算法2，根据需要重建的区域，创建一些不重叠的图片块patch
4. 将需要重建的patch送入LoMaR进行重建
5. 将重建好的块替换原来的图片块





### mask区域扩充算法







### 重建图片块生成算法





```
forward_decoder的返回值中，1表示掩盖，0为不掩
```





